{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzhou517/TEWH-Seizure-Project/blob/Convolutional-Autoencoder/DCAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIzKKoJQSSrd"
      },
      "source": [
        "# Deep Convolutional Autoencoder - CHB-MIT Data (Daoud et. al, 2019)\n",
        "## Rationale and Pseudocode\n",
        "\n",
        "Encoder:\n",
        "\n",
        "\n",
        "      Conv1d (relu activation function, filter size...)\n",
        "      MaxPooling\n",
        "      Conv1d\n",
        "      MaxPooling\n",
        "      Conv1d\n",
        "      MaxPooling\n",
        "      Conv1d\n",
        "\n",
        "\n",
        "Decoder:\n",
        "\n",
        "\n",
        "      Deconv\n",
        "      Upsample\n",
        "      Deconv\n",
        "      Upsample\n",
        "      Deconv\n",
        "      Upsample\n",
        "\n",
        "\n",
        "Compile via RMSprop optimizer and mean square error loss function.\n",
        "\n",
        "4. Reconstruct EEG segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmN7KupR7PET"
      },
      "source": [
        "# Code for DCAE\n",
        "\n",
        "Implementing what was detailed above according to Daoud 2019."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8LExi0X78Kj"
      },
      "source": [
        "## Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zpqQRRD75CL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import UpSampling1D\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Add\n",
        "from tensorflow.keras.layers import Input, Conv1D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9r9_AFI-gB1"
      },
      "source": [
        "## Making Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blem8BtpHHCT"
      },
      "source": [
        "### Encoder and Decoder - Training\n",
        "\n",
        "* Updated version uses:\n",
        "  * Andrew's advice\n",
        "  * New Daoud paper we found for DCAE + Bi-LSTM\n",
        "    * https://ieeexplore.ieee.org/abstract/document/8598447"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmoNJ-GwUr-G"
      },
      "source": [
        "Residual connections can help with overfitting. Lets say y defines the layer output, x the layer input, and W the convolution, a normal convolution takes the form of: y = W*x.\n",
        "\n",
        "A residual convolution is just: y = W*x + x\n",
        "\n",
        "If W changes the number of layers from c_in to c_out and a kernel size of K, define a second operator U that also takes c_in to c_out but does so with a kernel size of 1. Note, U is just matrix multiplication along the feature dimension. y = Wx + Ux.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjXtV7pqXGpf"
      },
      "source": [
        "def resadd(x: Tensor, y: Tensor) -> Tensor:\n",
        "    out = Add()([x, y])\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbsslZZAZmah",
        "outputId": "2c4e5796-a5ce-40ec-f35e-e2cda6d55bd9"
      },
      "source": [
        "time_length = 1280; ecg_channels = 23; in_ch = ecg_channels; out_ch = 46;\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "input_thingy=keras.Input(shape=(time_length, in_ch))\n",
        "x = layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1,activation='relu')(input_thingy) \n",
        "\n",
        "x= layers.BatchNormalization(axis=-1)(x)\n",
        "x= layers.MaxPooling1D(pool_size = 2, padding = 'valid')(x)\n",
        "in_ch = out_ch;\n",
        "out_ch *= 2\n",
        "skip = layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1,activation='relu')(x)\n",
        "\n",
        "x= layers.BatchNormalization(axis=-1)(x)\n",
        "x= layers.MaxPooling1D(pool_size = 2, padding = 'valid')(x)\n",
        "in_ch = out_ch;\n",
        "out_ch *= 2\n",
        "x = layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1,activation='relu')(x)\n",
        "\n",
        "x= layers.BatchNormalization(axis=-1)(x)\n",
        "bottleneck= layers.MaxPooling1D(pool_size = 2, padding = 'valid')(x)\n",
        "in_ch = out_ch;\n",
        "out_ch *= 2\n",
        "x=layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1)(x)\n",
        "  \n",
        "  # Your encoded product is of size: Batch x Time_Length / (2**network_depth) x out_ch * 2**(network_depth-1)\n",
        "\n",
        "\n",
        "\n",
        "out_ch = out_ch / 4\n",
        "\n",
        "x=layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1)(x)\n",
        "\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(axis=-1)(x)\n",
        "in_ch = out_ch;\n",
        "out_ch = out_ch // 2\n",
        "x=layers.UpSampling1D(size=2)(x)\n",
        "x=layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1)(x)\n",
        "\n",
        "\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(axis=-1)(x)\n",
        "in_ch = out_ch;\n",
        "out_ch = out_ch // 2\n",
        "x=layers.UpSampling1D(size=2)(x)\n",
        "x=layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1)(x)\n",
        "\n",
        "x=layers.ReLU()(x)\n",
        "x=layers.BatchNormalization(axis=-1)(x)\n",
        "in_ch = out_ch;\n",
        "out_ch = out_ch // 2\n",
        "x=layers.UpSampling1D(size=2)(x)\n",
        "x=layers.Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1)(x)\n",
        "\n",
        "x=layers.Dense(ecg_channels)(x)\n",
        "x= layers.Dense(ecg_channels)(x)\n",
        "\n",
        "autoencoder = keras.Model(input_thingy, x)\n",
        "autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss = 'mse')\n",
        "\n",
        "autoencoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 1280, 23)]        0         \n",
            "_________________________________________________________________\n",
            "conv1d_64 (Conv1D)           (None, 1280, 46)          3220      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 1280, 46)          184       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 640, 46)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_65 (Conv1D)           (None, 640, 92)           12788     \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 640, 92)           368       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 320, 92)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_66 (Conv1D)           (None, 320, 184)          50968     \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 320, 184)          736       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 160, 184)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_67 (Conv1D)           (None, 160, 368)          203504    \n",
            "_________________________________________________________________\n",
            "conv1d_68 (Conv1D)           (None, 160, 92)           101660    \n",
            "_________________________________________________________________\n",
            "re_lu_21 (ReLU)              (None, 160, 92)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 160, 92)           368       \n",
            "_________________________________________________________________\n",
            "up_sampling1d_14 (UpSampling (None, 320, 92)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_69 (Conv1D)           (None, 320, 46)           12742     \n",
            "_________________________________________________________________\n",
            "re_lu_22 (ReLU)              (None, 320, 46)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 320, 46)           184       \n",
            "_________________________________________________________________\n",
            "up_sampling1d_15 (UpSampling (None, 640, 46)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_70 (Conv1D)           (None, 640, 23)           3197      \n",
            "_________________________________________________________________\n",
            "re_lu_23 (ReLU)              (None, 640, 23)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 640, 23)           92        \n",
            "_________________________________________________________________\n",
            "up_sampling1d_16 (UpSampling (None, 1280, 23)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_71 (Conv1D)           (None, 1280, 11)          770       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1280, 23)          276       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1280, 23)          552       \n",
            "=================================================================\n",
            "Total params: 391,609\n",
            "Trainable params: 390,643\n",
            "Non-trainable params: 966\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ps2Scpr-fQK",
        "outputId": "c22fedb0-c015-45f1-ac22-433e1c402552"
      },
      "source": [
        "\n",
        "#SEQUENTIAL\n",
        "\n",
        "model = Sequential(name = 'Deep Convolutional Autoencoder')\n",
        "time_length = 1280; ecg_channels = 23; in_ch = ecg_channels; out_ch = 46; network_depth = 3\n",
        "\n",
        "model.add(Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1, input_shape=(time_length, in_ch)) )\n",
        "for n in range(network_depth):\n",
        "  model.add(keras.layers.ReLU())\n",
        "  model.add(BatchNormalization(axis=-1))\n",
        "  model.add(MaxPooling1D(pool_size = 2, padding = 'valid'))\n",
        "  in_ch = out_ch;\n",
        "  out_ch *= 2\n",
        "  model.add(Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1))\n",
        "  \n",
        "  # Your encoded product is of size: Batch x Time_Length / (2**network_depth) x out_ch * 2**(network_depth-1)\n",
        "\n",
        "out_ch = out_ch / 4\n",
        "\n",
        "model.add(Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1))\n",
        "for n in range(network_depth):\n",
        "  model.add(keras.layers.ReLU())\n",
        "  model.add(BatchNormalization(axis=-1))\n",
        "  in_ch = out_ch;\n",
        "  out_ch = out_ch // 2\n",
        "  model.add(UpSampling1D(size=2))\n",
        "  model.add(Conv1D(filters=out_ch, kernel_size=3, padding=\"same\", strides=1))\n",
        "\n",
        "model.add(keras.layers.Dense(ecg_channels))\n",
        "model.add(keras.layers.Dense(ecg_channels))\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.01), loss = 'mse')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Deep Convolutional Autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1280, 46)          3220      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 1280, 46)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1280, 46)          184       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 640, 46)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 640, 92)           12788     \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 640, 92)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 640, 92)           368       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 320, 92)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 320, 184)          50968     \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 320, 184)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 320, 184)          736       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 160, 184)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 160, 368)          203504    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 160, 92)           101660    \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 160, 92)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 160, 92)           368       \n",
            "_________________________________________________________________\n",
            "up_sampling1d (UpSampling1D) (None, 320, 92)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 320, 46)           12742     \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 320, 46)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 320, 46)           184       \n",
            "_________________________________________________________________\n",
            "up_sampling1d_1 (UpSampling1 (None, 640, 46)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 640, 23)           3197      \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 640, 23)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 640, 23)           92        \n",
            "_________________________________________________________________\n",
            "up_sampling1d_2 (UpSampling1 (None, 1280, 23)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 1280, 11)          770       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1280, 23)          276       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1280, 23)          552       \n",
            "=================================================================\n",
            "Total params: 391,609\n",
            "Trainable params: 390,643\n",
            "Non-trainable params: 966\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}