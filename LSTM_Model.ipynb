{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jzhou517/TEWH-Seizure-Project/blob/LSTM/LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVt53wWhWzw3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential \n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pnMVq_HaE3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970e5a2d-4a64-4538-9439-f2f840ec8c17"
      },
      "source": [
        "# defining model \n",
        "t_timesteps = 1280 #from encoded input, for now we can test on the raw data we have\n",
        "features_per_step = 23 #the channels can be features for now\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(20, dropout=0.1, recurrent_dropout=0.5), input_shape=(t_timesteps, features_per_step)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.compile(optimizer='rmsprop', loss='mse')\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_5 (Bidirection (None, 40)                7040      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 7,081\n",
            "Trainable params: 7,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkuH_8B8HDGA"
      },
      "source": [
        "#\n",
        "i=0\n",
        "for epoch in range(len(X_train)):\n",
        "    X= X_train(i)\n",
        "    y= y_train(i)\n",
        "    model.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
        "    i=i+1\n",
        "# evaluate LSTM\n",
        "X,y = X_train(i)\n",
        "y=Y_test(i)\n",
        "yhat = model.predict_classes(X, verbose=0)\n",
        "for i in range(n_timesteps):\n",
        "    print('Expected:', y[0, i], 'Predicted', y_hat[0, i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}